{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1880d72f",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d745ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10d356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_miami_mls(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the Miami MLS dataset with advanced feature engineering,\n",
    "    including PropertySubType consolidation.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting preprocessing for: {filepath} ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Successfully loaded data. Initial shape: {df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Apply Initial Rules ---\n",
    "    # Note: We are now using PropertySubType, so PropertyType is less critical\n",
    "    if 'PropertyType' in df.columns: df = df[df['PropertyType'] != 'ResidentialLease']\n",
    "    if 'ClosePrice' in df.columns: df = df[df['ClosePrice'].between(10_000, 25_000_000)]\n",
    "    \n",
    "    # --- NEW: Consolidate PropertySubType ---\n",
    "    if 'PropertySubType' in df.columns:\n",
    "        print(\"Consolidating PropertySubType categories...\")\n",
    "        \n",
    "        # Define categories for grouping\n",
    "        condo_group = ['Condominium', 'Townhouse', 'Apartment', 'Villa', 'StockCooperative']\n",
    "        sfr_group = ['SingleFamilyResidence', 'MobileHome']\n",
    "        multi_family_group = ['MultiFamily', 'Duplex', 'Residential']\n",
    "        \n",
    "        # Define categories to remove\n",
    "        remove_group = ['Timeshare', 'HotelMotel', 'BoatSlip', 'Other', 'Office', 'Industrial']\n",
    "        \n",
    "        # First, remove the unwanted subtypes\n",
    "        df = df[~df['PropertySubType'].isin(remove_group)]\n",
    "        \n",
    "        # Create a mapping dictionary for the new, clean categories\n",
    "        # --- MODIFIED LINE ---\n",
    "        mapping = {sub_type: 'Condominium' for sub_type in condo_group}\n",
    "        mapping.update({sub_type: 'Single Family Residence' for sub_type in sfr_group})\n",
    "        mapping.update({sub_type: 'Multi Family' for sub_type in multi_family_group})\n",
    "        \n",
    "        # Apply the mapping to create a new 'PropertyCategory' column\n",
    "        df['PropertyCategory'] = df['PropertySubType'].map(mapping)\n",
    "        \n",
    "        # Drop rows where the category is now NaN (i.e., not in our mapping)\n",
    "        df.dropna(subset=['PropertyCategory'], inplace=True)\n",
    "\n",
    "    # --- Clean and Standardize ZIP Code Column ---\n",
    "    if 'ZIP' in df.columns:\n",
    "        df['ZIP'] = df['ZIP'].astype(str).fillna('').str.replace(r'[^0-9]', '', regex=True).str.zfill(5).str.slice(0, 5)\n",
    "\n",
    "    # --- Condo-Specific Logic (Now based on PropertyCategory) ---\n",
    "    if 'PropertyCategory' in df.columns:\n",
    "        print(\"Applying logic for attached properties (condos, townhouses)...\")\n",
    "        # --- MODIFIED LINE ---\n",
    "        df['IsAttached'] = np.where(df['PropertyCategory'] == 'Condominium', 1, 0)\n",
    "        if 'PropertyLot_Square_footage' in df.columns:\n",
    "            # --- MODIFIED LINE ---\n",
    "            df.loc[df['PropertyCategory'] == 'Condominium', 'PropertyLot_Square_footage'] = 0\n",
    "\n",
    "    # --- Garage and Age Features ---\n",
    "    if 'GarageYN' in df.columns and 'GarageSpaces' in df.columns:\n",
    "        condition = (df['GarageYN'] == True) & (df['GarageSpaces'].isnull())\n",
    "        df.loc[condition, 'GarageSpaces'] = 1\n",
    "        df = df.drop(columns=['GarageYN'])\n",
    "    if 'YearBuilt' in df.columns:\n",
    "        df['PropertyAge'] = 2025 - df['YearBuilt']\n",
    "        df = df.drop(columns=['YearBuilt'])\n",
    "    \n",
    "    # --- Expanded Description-Based Feature Extraction ---\n",
    "    if 'Description' in df.columns:\n",
    "        print(\"Extracting new features from description...\")\n",
    "        df['Description'] = df['Description'].astype(str).fillna('').str.lower()\n",
    "        pool_keywords = ['pool', 'swimming', 'poolside','Private Pool', 'in-ground pool', 'heated pool', 'pool area', 'pool deck', 'spa', 'jacuzzi', 'hot tub']\n",
    "        df['HasPrivatePool'] = df['Description'].str.contains('|'.join(pool_keywords), case=False).astype(int)\n",
    "        remodel_keywords = ['remodeled', 'renovated', 'updated', 'newly done', 'fully upgraded', 'modernized', 'recently renovated', 'new finishes', 'newly remodeled', 'newly renovated','New','New Construction', 'Newly Built']\n",
    "        df['IsRemodeled'] = df['Description'].str.contains('|'.join(remodel_keywords), case=False).astype(int)\n",
    "        roof_keywords = ['new roof', 'roof replaced', 'recent roof']\n",
    "        df['HasNewRoof'] = df['Description'].str.contains('|'.join(roof_keywords), case=False).astype(int)\n",
    "        kitchen_keywords = ['granite', 'quartz', 'stainless steel', 'new kitchen', 'updated kitchen', 'gourmet kitchen','Chef\\'s kitchen', 'modern kitchen', 'luxury kitchen', 'kitchen remodel', 'kitchen renovation', 'kitchen upgrade']\n",
    "        df['HasUpgradedKitchen'] = df['Description'].str.contains('|'.join(kitchen_keywords), case=False).astype(int)\n",
    "\n",
    "    if 'ClosePrice' in df.columns:\n",
    "        df['IsLuxury'] = (df['ClosePrice'] > 1_000_000).astype(int)\n",
    "    \n",
    "    print(f\"Preprocessing complete. Final data shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def engineer_features(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Engineers advanced features for ZIP and City based on the training data.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Advanced Feature Engineering...\")\n",
    "    for df in [X_train, X_test]:\n",
    "        df['BathBedRatio'] = (df['Baths'] / df['Beds']).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        df['HouseLotRatio'] = (df['SquareFootage'] / df['PropertyLot_Square_footage']).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    train_with_target = X_train.join(y_train)\n",
    "    \n",
    "    # --- ZIP Code Features ---\n",
    "    if 'ZIP' in X_train.columns:\n",
    "        zip_stats = X_train.groupby('ZIP').agg({'SquareFootage': ['mean', 'median'], 'PropertyAge': ['mean', 'median']})\n",
    "        zip_stats.columns = ['ZIP_' + '_'.join(col).strip() for col in zip_stats.columns.values]\n",
    "        X_train = X_train.merge(zip_stats, on='ZIP', how='left')\n",
    "        X_test = X_test.merge(zip_stats, on='ZIP', how='left')\n",
    "        for col in zip_stats.columns: X_test[col] = X_test[col].fillna(zip_stats[col].mean())\n",
    "        print(\"Created neighborhood features for ZIP code.\")\n",
    "    else:\n",
    "        zip_stats = None\n",
    "\n",
    "    # --- City Features ---\n",
    "    if 'City' in X_train.columns:\n",
    "        city_stats = train_with_target.groupby('City').agg({\n",
    "            'ClosePrice': lambda x: x.median(),\n",
    "            'SquareFootage': lambda x: x.median(),\n",
    "            'Beds': lambda x: x.median()\n",
    "        })\n",
    "        city_stats['PricePerSqFt_by_City'] = city_stats['ClosePrice'] / city_stats['SquareFootage']\n",
    "        city_stats = city_stats.drop(columns='ClosePrice')\n",
    "        city_stats.columns = ['MedianSqFt_by_City', 'MedianBeds_by_City', 'PricePerSqFt_by_City']\n",
    "        \n",
    "        X_train = X_train.merge(city_stats, on='City', how='left')\n",
    "        X_test = X_test.merge(city_stats, on='City', how='left')\n",
    "        for col in city_stats.columns: X_test[col] = X_test[col].fillna(city_stats[col].mean())\n",
    "        print(\"Created market features for City.\")\n",
    "    else:\n",
    "        city_stats = None\n",
    "\n",
    "    print(\"Feature Engineering complete.\")\n",
    "    return X_train, X_test, zip_stats, city_stats\n",
    "\n",
    "# --- 1. Load and Preprocess Data ---\n",
    "df = preprocess_miami_mls('miami_mls4.csv')\n",
    "\n",
    "if not df.empty:\n",
    "    # --- 2. Feature Selection & Initial Split ---\n",
    "    features = [\n",
    "        'Beds', 'Baths', 'HalfBaths', 'SquareFootage', 'PropertyLot_Square_footage',\n",
    "        'GarageSpaces', 'PropertyAge', 'IsLuxury', 'IsRemodeled',\n",
    "        'HasPrivatePool', 'City', 'PropertyCategory', 'ZIP', # Using new PropertyCategory\n",
    "        'IsAttached', 'HasNewRoof', 'HasUpgradedKitchen' # Using new IsAttached\n",
    "    ]\n",
    "    target = 'ClosePrice'\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    X = df[available_features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- 3. Engineer Advanced Features ---\n",
    "    X_train, X_test, zip_stats_to_save, city_stats_to_save = engineer_features(X_train.copy(), y_train, X_test.copy())\n",
    "\n",
    "    # --- 4. Handle Categorical Features & Finalize DataFrames ---\n",
    "    for col in ['ZIP', 'City']:\n",
    "        if col in X_train.columns: X_train = X_train.drop(columns=[col])\n",
    "        if col in X_test.columns: X_test = X_test.drop(columns=[col])\n",
    "    \n",
    "    if 'PropertyCategory' in X_train.columns:\n",
    "        X_train = pd.get_dummies(X_train, columns=['PropertyCategory'], drop_first=True)\n",
    "        X_test = pd.get_dummies(X_test, columns=['PropertyCategory'], drop_first=True)\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    # --- 5. Log Transform the Target Variable ---\n",
    "    y_train_log = np.log1p(y_train)\n",
    "\n",
    "    # --- 6. Hyperparameter Tuning ---\n",
    "    print(\"\\n--- Starting Hyperparameter Tuning with RandomizedSearchCV ---\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [500, 1000, 1500], 'learning_rate': [0.02, 0.05, 0.1],\n",
    "        'max_depth': [5, 7, 9], 'subsample': [0.7, 0.8], 'colsample_bytree': [0.7, 0.8],\n",
    "    }\n",
    "    xgb_tuner = xgb.XGBRegressor(objective='reg:quantileerror', quantile_alpha=0.5, random_state=42, n_jobs=-1)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=xgb_tuner, param_distributions=param_grid, n_iter=6,\n",
    "        scoring='neg_mean_absolute_error', cv=3, verbose=1, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train, y_train_log)\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "    # --- 7. Train Final Quantile Models with Best Parameters ---\n",
    "    quantiles = {'low': 0.10, 'mid': 0.50, 'high': 0.90}\n",
    "    models = {}\n",
    "    for name, q in quantiles.items():\n",
    "        print(f\"Training final XGBoost model for {name} quantile ({q:.2f})...\")\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:quantileerror', quantile_alpha=q, \n",
    "            random_state=42, n_jobs=-1, early_stopping_rounds=50, **best_params\n",
    "        )\n",
    "        model.fit(X_train, y_train_log, eval_set=[(X_test, np.log1p(y_test))], verbose=False)\n",
    "        models[name] = model\n",
    "        print(f\"{name.capitalize()} model training complete. ✅\")\n",
    "\n",
    "    # --- 8. Make Predictions and Evaluate ---\n",
    "    y_pred_median = np.expm1(models['mid'].predict(X_test))\n",
    "    mae = mean_absolute_error(y_test, y_pred_median)\n",
    "    r2 = r2_score(y_test, y_pred_median)\n",
    "    print(\"\\n--- Model Evaluation (based on Median Prediction) ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "    print(f\"R-squared ($R^2$): {r2:.4f}\")\n",
    "\n",
    "    # --- 9. SAVE ALL ARTIFACTS ---\n",
    "    print(\"\\n--- Saving all necessary artifacts... ---\")\n",
    "    for name, model in models.items():\n",
    "        model.save_model(f\"xgb_model_{name}.json\")\n",
    "        print(f\"Saved model to xgb_model_{name}.json\")\n",
    "\n",
    "    if zip_stats_to_save is not None:\n",
    "        joblib.dump(zip_stats_to_save, 'zip_stats.joblib')\n",
    "        print(\"Saved zip_stats lookup data to zip_stats.joblib\")\n",
    "    if city_stats_to_save is not None:\n",
    "        joblib.dump(city_stats_to_save, 'city_stats.joblib')\n",
    "        print(\"Saved city_stats lookup data to city_stats.joblib\")\n",
    "\n",
    "    model_columns = X_train.columns\n",
    "    joblib.dump(model_columns, 'model_columns.joblib')\n",
    "    print(\"Saved model columns to model_columns.joblib\")\n",
    "    print(\"\\nArtifacts saved successfully. You are ready to run the app.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nCould not run model training because the DataFrame is empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
